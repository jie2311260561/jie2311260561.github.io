---
layout: post
title:  "个人过程记录笔记"
date:   2021-8-13
categories: note
tags: Shell cc
excerpt: 个人记录
--- 






# 个人笔记

## 工作架构： 

1. 通过开通编译服务器进行编译。 

   编译服务器b 申请

2. 通过编译服务器利用git下载代码到编译服务器。 
   git  用户名申请

3. 上internet需求，要申请D网云桌面。
   allwinner在线协作系统

### 网络段 

个人是B网 可以访问  内网  外网的业务   C  K 网需要IT部门安装软件使用

## 解决软件安装

1. 编译服务器  导师代为申请提交工单
2. Git
3. vscode

## 工具软件

1. qq wechat DingTask

## 编译服务器(B网)

- 地址`172.16.7.89`
- 登录账号 SSH `kunyao` Samba  `.\kunyao`

- 登录密码SSH `Kirin125` Samba `123456`

  samba 服务器 使用 文件资源管理器 没有办法访问 使用`win+R` 可以访问 然后使用账号进行连接

  

- USB烧录接口的访问

## 版本管理工具 repo

repo 是git 的python 封装  清单文件是xml 的格式

### repo 拉取命令

` repo init -u ssh://ppgerrit.com/Mstar648/manifest.git -b 648_cultraview -m ppos4.5.0_cultraview.xml`

- -u：指定一个URL，其连接到一个manifest仓库

- -b：选择manifest仓库中的一个特殊分支

- -m：在manifest仓库中选择一个xml文件

  

### 同步代码

​	repo sync	



## 自己在获取服务器资源上的努力

没有权限访问外网，所以下载不了东西，不能使用repo 拉取代码



repo init -u ssh://verify@172.16.1.49/git_repo/D1_Tina_Open/manifest.git -b master -m tina-d1-open.xml



不能下载SDK 先研究一下



犯了一个及其致命的错误  就是没有设置 git 的 user 信息  同时下载服务器的路径还填错了，太致命了



经过这些操作  完成了 Hello Word 的输出  并整理了文档



## 摄像头 下个阶段

### USB carmer 成功使用

USB carmer 使用opencv 进行调用  

编译参数

```
cmake -D CMAKE_BUILD_TYPE=RELEASE
-D CMAKE_INSTALL_PREFIX=/home/gaojies/workspace/d1-tina-open/tools/opencv/install
-D OPENCV_GENERATE_PKGCONFIG=ON
-D INSTALL_PYTHON_EXAMPLES=ON
-D INSTALL_C_EXAMPLES=ON
-D OPENCV_EXTRA_MODULES_PATH= /home/cht/opencv4/opencv_contrib-4.0.1/modules
-D OPENCV_EXAMPLES=ON ..
```

Video4Linux2(Video for Linux Two, 简称V4L2)是Linux中关于视频设备的驱动框架，为上层访问底层的视频设备提供统一接口。V4L2主要支持三类设备：视频输入输出设备、VBI设备和Radio设备，分别会在/dev目录下产生videoX、vbiX和radioX设备节点，其中X是0,1,2等的数字。如USB摄像头是我们常见的视频输入设备。FFmpeg和OpenCV对V4L2均支持。

使用V4L2库完成摄像头图片捕捉，获取成功保存为一张图片。

保存图片之后，在HDMI上显示摄像头画面，然后将当前的画面的图片进行截取保存。

​	在test/camerademo/test.c 程序可以实现

​	在test/usbvamer/photo.c 程序编译没有问题，会在mnmap的时候挂掉，还不知道是怎么回事。

继续尝试使用opencv来进行摄像头数据采集。

### USB carmer 输出HDMI

### 准备一下摄像头摄影的demo



### ffmpeg编译成功，摄像头准备好之后就可以准备数据集了



./configure --cross-prefix=

## FFmpeg编译使用及环境

### 编译

值得一提的是，ffmpeg 不能在 原来的x86的环境中编译，需要重新创建一个编译目录  就是把代码重新解压缩一份  很关键!!!

```
./configure --enable-cross-compile --prefix=./install --enable-shared --target-os=linux --arch=riscv --enable-gpl --extra-cflags="-fPIC" --extra-ldflags=-Wl,-Bsymbolic --extra-libs="-lpthread -lm" --cross-prefix=riscv64-unknown-linux-gnu-

make -j16

make install
```

### 板子环境生效

```
export LD_LIBRARY_PATH=/mnt/SDCARD/install/lib:$LD_LIBRARY_PATH
```

### 使用 

#### 录制视频

```
ffmpeg -hide_banner -s 1920*1080 -i /dev/video0 out2.avi
```

#### 视频转图片

```css
ffmpeg -i test.mp4 -r 1 -f image2 img-%3d.jpeg
```

## 玩了一下ncnn

值得一提的是ncnn是nihui大佬优化的，仅支持最新的交叉编译工具，老的编译不会通过  ,ncnn 好像是支持了这么多的神经网络模型推断

```
[100%] Built target squeezenetssd
[100%] Built target peleenetssd_seg
[100%] Built target benchncnn
[100%] Built target simplepose
[100%] Built target mobilenetv2ssdlite
[100%] Built target squeezenet
[100%] Built target yolov3
[100%] Built target yolov2
[100%] Built target fasterrcnn
[100%] Built target nanodet
[100%] Built target yolov5
[100%] Built target shufflenetv2
[100%] Built target scrfd
[100%] Built target retinaface
[100%] Built target mobilenetssd
[100%] Built target rfcn
[100%] Built target squeezenet_c_api
[100%] Built target yolact
```

## 编译opencv的问题

 有个在编译工具里  的 && 的符号 可以删掉再次编译   确保能编译过去 然后再把对应的编译链的 文件修改回去 嘻嘻

https://github.com/advancedtelematic/aktualizr/issues/1427

这是一个很好的文章

undefined reference to `__atomic_compare_exchange_1'

没用定义原子操作，提出了两种解决方法   

1、修改源码

2、连接到risc-v的原子操作库  

成功编译出来

在运行的过程中  在 库中没有找到  GLIBC2.29 和 GLIBCXX3.4.26



```
./opencvcamer: /lib/ld-linux-riscv64xthead-lp64d.so.1: version `GLIBC_2.29' not found (required by /usr/lib64xthead/lp64d/libopencv_world.so)
./opencvcamer: /lib64xthead/lp64d/libstdc++.so.6: version `GLIBCXX_3.4.26' not found (required by /usr/lib64xthead/lp64d/libopencv_world.so)
./opencvcamer: /lib64xthead/lp64d/libpthread.so.0: version `GLIBC_2.29' not found (required by /usr/lib64xthead/lp64d/libopencv_world.so)
./opencvcamer: /lib64xthead/lp64d/libpthread.so.0: version `GLIBC_2.29' not found (required by /usr/lib64xthead/lp64d/libatomic.so.1)

```

要去新的编译链的地方把这些东西找回来

重新移植了 lib64x 把系统搞没了 重新烧录 系统 再 继续看看

opencv 一直出现问题   移植失败  准备使用 cmake-gui 去试试效果  选择tina中的编译器  回去再看



### opencv的问题

目前存在opencv摄像头打不开的情况。



## pack 打包

```
./device/config/chips/d1/configs/default/sys_partition.fex   规划分区表的文件 
name：分区名称
size:分区的大小
downloadfile:下载的文件



打包的流程：

在shell 脚本里实现了 pack 的函数  function pack 函数最终调用的是 ` tina/scripts/pack_img.sh `

这个脚本文件，这个脚本实现了打包的流程

do_prepare 文件拷贝阶段 

APP PART DOWNLOAD_FILE  成功打印



修改分区后的文件  已经成功实现 pack 并烧录
这里的问题 经过dalao 的指导后明白了他的功能性过程  美滋滋
```





## 按键驱动 

查看全志文档，D1 开发板的 dts 是

`/home/gaojies/workspace/d1-tina-open/lichee/linux-5.4/arch/riscv/boot/dts/sunxi` 在这里，对应的IO的驱动是

```
lichee/linux-5.4/drivers/input/keyboard/gpio-keys-polled.c  //gpio poll 
keylichee/linux-5.4/drivers/input/keyboard/gpio-keys.c//interrupt key
```



 ① 时不时进房间看一下：**查询方式** 简单，但是累 ② 进去房间陪小孩一起睡觉，小孩醒了会吵醒她：**休眠-唤醒** 不累，但是妈妈干不了活了 ③ 妈妈要干很多活，但是可以陪小孩睡一会，定个闹钟：**poll方式** 要浪费点时间，但是可以继续干活。 妈妈要么是被小孩吵醒，要么是被闹钟吵醒。 ④ 妈妈在客厅干活，小孩醒了他会自己走出房门告诉妈妈：**异步通知** 妈妈、小孩互不耽误

使用休眠-唤醒的方式等待某个事件发生时，有一个缺点：**等待的时间可能很久**。我们可以加上一个**超时时间**，这时就可以使用poll机制。 ① APP不知道驱动程序中是否有数据，可以先调用poll函数查询一下，poll函数可以传入超时时间； ② APP进入内核态，调用到驱动程序的poll函数，如果有数据的话立刻返回； ③ 如果发现没有数据时就**休眠一段时间**； ④ 当有数据时，比如当按下按键时，驱动程序的中断服务程序被调用，它会记录数据、唤醒APP； ⑤ 当超时时间到了之后，内核也会唤醒APP； ⑥ APP根据poll函数的返回值就可以知道是否有数据，如果有数据就调用read得到数据

## linux内核文件系统

* proc 虚拟文件系统，包括了很多系统信息，都可以通过文本流来查看进程信息。
* tmpfs 虚拟内存文件系统，使用内存作为临时存储分区，掉电后数据会丢失，创建时不需要mkfs等格式化
  * 因为殷蹙的访问速度高于flash，可以提高存储效率，避免对flash频繁读写。
* devfs 设备文件提供类似于文件的方法来管理位于、/dev目录下的设备。
* sysfs 虚拟文件系统。

## RISCV优势

来自指令集层面的可扩展性，RV32G标准 乘法 除法 RV32M 

浮点操作 RV32F 和 RV32D

原子操作 RV32A

不同字长的指令对解码部件要求极为严格。RISCV对于所有指令 要读写的寄存器 标识符 总在同一位置，意味者指令解码之前，就可以先开始访问存储器。符号位 总在最高位 意味着关键路径的立即数符号扩展，可以在指令解码之前进行。



RISCV 汇编器 

汇编开头是一些汇编指示符号他们是汇编器的命令，具有告诉汇编器代码和数据的位置，给程序中使用特定代码和数据常量等作用。

* .test 进入代码段
* .align 2 后续代码按照2^2 字节对齐
* .globl main 声明全局符号  main
* .section .rodata 进入只读数据段
* .balign 4 数据按照4字节对齐
* .string "Hello,%s!\n"
* .string "word" 创建空字符结尾的字符串

![5BC32136-30BB-446b-8E4D-A5C3B68CE07E](D:\BedRock\allwinnerofcode\myimgh\5BC32136-30BB-446b-8E4D-A5C3B68CE07E.png)

## SD卡

默认插进去为 mmcblk0 挂载它

## 编译X264

./configure --prefix=output/riscv --host= riscv-linux --enable-shared --disable-asm --cross-prefix=



碰见文件不能解析  其实推荐使用dos2unix 工具，这里是能使用vim 一句一句解析  

版本问题不对也需要 unix 文件格式 然后就可以顺利完成编译

```shell
# 最终的编译指令
./configure --prefix=build --host=arm-linux --enable-shared --disable-asm --cross-prefix=riscv64-unknown-linux-gnu- --sysroot=/home/gaojies/workspace/d1-tina-open/prebuilt/gcc/linux-x86/riscv/toolchain-thead-glibc/riscv64-glibc-gcc-thead_20200702/sysroot --disable-opencl
```



## 服务器训练环境搭建

SSL BZ2 LZMA 库 这些需要注意 （Python）

不注意编译出来的Python不能用

## getenent

 需要加载gt9xxnew_ts.ko 驱动

```
insmod gt9xxnew_ts.ko
```

~/workspace/d1-tina-open/device/config/chips/d1/configs/nezha/linux/board.dts

ctp@14





又是一点点小细节！！！！

## mnipi屏幕驱动

使用LVGL直接开跑！冲冲冲！

## 模型转化  之 yolov5



python models/export.py --weights runs/train/exp2/weights/best.pt --img 640 --batch 1

python -m onnxsim run s/train/exp2/weights/best.onnx best-sim.onnx

onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Node (Mul_915) Op (Mul) [ShapeInferenceError] 尺寸不兼容

通过验证是ONNX模型本身在加载的过程中就存在这样的问题。而模型本身，我自己训练的和从官方下载下来的模型都不应该有问题。  再尝试一下官方模型来试试？

确信这是模型转化 为ONNX 的问题  再github 上反馈 找到是 torch 版本的问题 卸载了 1.9.0 的torch 安装一个 1.6.0 的试试



